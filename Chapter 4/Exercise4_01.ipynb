{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Examples in the Dataset =  908\n",
      "Number of Features for each example =  6\n",
      "Output Range = [0.053000, 9.612000]\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "import pandas as pd\n",
    "\n",
    "colnames = ['CIC0', 'SM1_Dz(Z)', 'GATS1i', 'NdsCH', 'NdssC','MLOGP', 'LC50']\n",
    "data = pd.read_csv('../data/qsar_fish_toxicity.csv', sep=';', names=colnames)\n",
    "X = data.drop('LC50', axis=1)\n",
    "y = data['LC50']\n",
    "\n",
    "# Print the sizes of the dataset\n",
    "print(\"Number of Examples in the Dataset = \", X.shape[0])\n",
    "print(\"Number of Features for each example = \", X.shape[1])\n",
    "# print output range\n",
    "print(\"Output Range = [%f, %f]\" %(min(y), max(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "# Create the function that returns the keras model\n",
    "def build_model():\n",
    "    # build the Keras model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    # Compile the model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    # return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the scikit-Learn interface for the keras model\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "YourModel = KerasRegressor(build_fn= build_model, epochs=100, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "37/37 [==============================] - 0s 866us/step - loss: 2.2382\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 1.4959\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 1.3893\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 946us/step - loss: 1.3084\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 1.2425\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 1.1967\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1565\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 1.1258\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1002\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0802\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 1.0576\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 1.0424\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 1.0360\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 1.0232\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 1.0087\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 1.0005\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9926\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 0s 946us/step - loss: 0.9844\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9762\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9773\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.9645\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 0s 999us/step - loss: 0.9648\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 0.9603\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.9533\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 0s 837us/step - loss: 0.9542\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 0.9428\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 0.9414\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 0.9343\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.9320\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 0.9305\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 0s 837us/step - loss: 0.9248\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 0.9203\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.9185\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 0.9153\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 0.9106\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 0s 999us/step - loss: 0.9185\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 0.9110\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 0s 810us/step - loss: 0.9088\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9043\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8991\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8964\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8971\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9033\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8903\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8897\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8868\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8856\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8911\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 0s 999us/step - loss: 0.8942\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8798\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8817\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.8826\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8872\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8731\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8792\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 0s 916us/step - loss: 0.8703\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 0s 946us/step - loss: 0.8714\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8693\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 0.8705\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8758\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8680\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 0.8663\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.8619\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 0.8625\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 0s 1000us/step - loss: 0.8625\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8664\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8593\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8689\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8609\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8572\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 0s 817us/step - loss: 0.8572\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 0.8555\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 0s 973us/step - loss: 0.8563\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 0s 999us/step - loss: 0.8624\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 0.8623\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 0s 837us/step - loss: 0.8590\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 0s 1000us/step - loss: 0.8537\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 0.8520\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.8544\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.8613\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 0s 837us/step - loss: 0.8499\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 0s 918us/step - loss: 0.8581\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8523\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 0.8486\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 0s 918us/step - loss: 0.8484\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.8544\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 0s 918us/step - loss: 0.8522\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.8518\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 0.8548\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.8482\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 0.8487\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 0s 918us/step - loss: 0.8525\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8525\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 0.8530\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 0.8543\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8478\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8466\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8466\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 0.8454\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 972us/step - loss: 0.8445\n",
      "10/10 [==============================] - 0s 918us/step\n",
      "Epoch 1/100\n",
      " 1/37 [..............................] - ETA: 0s - loss: 23.2046WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0027s). Check your callbacks.\n",
      "37/37 [==============================] - 0s 965us/step - loss: 17.0778\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 837us/step - loss: 10.4873\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 810us/step - loss: 6.6329\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 4.5783\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 3.5549\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 892us/step - loss: 3.0671\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.7737\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.5475\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 2.3496\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 2.1679\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 918us/step - loss: 2.0046\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 1.8587\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 1.7278\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.6112\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 1.5066\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.4207\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 0s 837us/step - loss: 1.3419\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 1.2781\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 1.2190\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 0s 783us/step - loss: 1.1696\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 1.1223\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 1.0807\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 0s 837us/step - loss: 1.0468\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 0s 999us/step - loss: 1.0095\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 0s 837us/step - loss: 0.9772\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 0s 837us/step - loss: 0.9470\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 0s 837us/step - loss: 0.9205\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 0.9025\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 0s 892us/step - loss: 0.8920\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8858\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.8850\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 0.8736\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.8665\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8640\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8611\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8585\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 0s 999us/step - loss: 0.8633\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 0s 999us/step - loss: 0.8527\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8484\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8474\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8430\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8424\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8420\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.8391\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8503\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8353\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8355\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8328\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8338\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 0.8291\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 0.8272\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 0.8258\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 0s 946us/step - loss: 0.8255\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8249\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8220\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 0s 973us/step - loss: 0.8242\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 0s 892us/step - loss: 0.8187\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 0.8201\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8230\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 0.8200\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8132\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.8161\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8116\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8106\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8151\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8081\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 0s 939us/step - loss: 0.8082\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 0s 939us/step - loss: 0.8067\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8050\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8083\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.7990\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8099\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8037\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8048\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7993\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7986\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7969\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7987\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7961\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 0s 968us/step - loss: 0.7962\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7963\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7948\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7918\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7921\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7933\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7917\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7956\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7913\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7888\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7881\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 0s 939us/step - loss: 0.7973\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 0s 996us/step - loss: 0.7901\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7892\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.7862\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.7872\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 2ms/step - loss: 0.7866\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7868\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.7845\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7848\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7858\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "37/37 [==============================] - 0s 999us/step - loss: 20.4415\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 13.3454\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 973us/step - loss: 7.9778\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 4.3735\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 977us/step - loss: 2.5027\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.8088\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 903us/step - loss: 1.6059\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.5350\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.4863\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.4448\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.4049\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 0s 839us/step - loss: 1.3687\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 0s 983us/step - loss: 1.3344\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3035\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 0s 944us/step - loss: 1.2755\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 0s 976us/step - loss: 1.2493\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2239\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 0s 905us/step - loss: 1.1982\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 0s 835us/step - loss: 1.1780\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 0s 841us/step - loss: 1.1541\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 0s 832us/step - loss: 1.1379\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1184\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 1.0977\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 0s 795us/step - loss: 1.0782\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 0s 867us/step - loss: 1.0612\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 0s 939us/step - loss: 1.0466\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 0s 867us/step - loss: 1.0334\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 1.0194\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 1.0079\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 0s 1000us/step - loss: 0.9973\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9861\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 0.9743\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9648\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9561\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9482\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9426\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9341\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 0s 837us/step - loss: 0.9275\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 0.9218\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 0s 892us/step - loss: 0.9153\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.9107\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 0s 1000us/step - loss: 0.9060\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9017\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8969\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8933\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8917\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8858\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 0s 867us/step - loss: 0.8889\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 0s 839us/step - loss: 0.8815\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8778\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.8750\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8792\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 0s 795us/step - loss: 0.8706\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 0s 808us/step - loss: 0.8684\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 0s 723us/step - loss: 0.8670\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 0s 723us/step - loss: 0.8621\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 0s 795us/step - loss: 0.8620\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 0s 867us/step - loss: 0.8607\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 0s 940us/step - loss: 0.8593\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8624\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8576\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - 0s 795us/step - loss: 0.8531\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8540\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8519\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 0s 867us/step - loss: 0.8502\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8491\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8504\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 0s 939us/step - loss: 0.8456\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8460\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 0s 940us/step - loss: 0.8453\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8432\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8466\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8461\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8411\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 0s 795us/step - loss: 0.8412\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 0s 795us/step - loss: 0.8408\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 0s 867us/step - loss: 0.8382\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8374\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8432\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 0.8376\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 0.8349\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8327\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 0s 980us/step - loss: 0.8345\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 0s 982us/step - loss: 0.8382\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8319\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 0s 982us/step - loss: 0.8344\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 0s 737us/step - loss: 0.8303\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 0s 901us/step - loss: 0.8291\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 0s 819us/step - loss: 0.8282\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 0s 737us/step - loss: 0.8282\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 0s 867us/step - loss: 0.8293\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 0s 704us/step - loss: 0.8301\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 0s 655us/step - loss: 0.8290\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8270\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8270\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8355\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8303\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8240\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8287\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8252\n",
      "10/10 [==============================] - 0s 840us/step\n",
      "Epoch 1/100\n",
      "37/37 [==============================] - 0s 873us/step - loss: 11.4895\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 869us/step - loss: 8.4542\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 999us/step - loss: 5.6998\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 3.6850\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 928us/step - loss: 2.5572\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 2.1026\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 902us/step - loss: 1.9488\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 1.8661\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 0s 918us/step - loss: 1.7960\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 1.7289\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.6668\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 0s 812us/step - loss: 1.6108\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 1.5570\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 0s 918us/step - loss: 1.5090\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 0s 918us/step - loss: 1.4633\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.4227\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3855\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3503\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3212\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2904\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2670\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 1.2427\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2238\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2039\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 0s 977us/step - loss: 1.1872\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1733\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1620\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 0s 983us/step - loss: 1.1489\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1366\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1255\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1177\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1092\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1006\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0943\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0886\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0815\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0758\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0737\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0671\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.0613\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0608\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 0s 883us/step - loss: 1.0543\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 1.0498\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 1.0470\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 0s 857us/step - loss: 1.0444\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 1.0391\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 0s 919us/step - loss: 1.0388\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 1.0358\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0322\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 0s 973us/step - loss: 1.0308\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 0s 918us/step - loss: 1.0276\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 1.0249\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 1.0225\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 0s 1000us/step - loss: 1.0224\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 1.0180\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 1.0132\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 1.0120\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 1.0098\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 1.0075\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0060\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0036\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0044\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9987\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 0s 999us/step - loss: 0.9996\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9977\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9938\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9956\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9937\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9879\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9880\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9936\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 0s 999us/step - loss: 0.9837\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9828\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 0.9820\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.9805\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 0.9784\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9775\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 0s 999us/step - loss: 0.9785\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 0s 1000us/step - loss: 0.9743\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 0.9715\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.9709\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 0s 918us/step - loss: 0.9703\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.9683\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.9673\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9669\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9643\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9646\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9648\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9605\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9626\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9644\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9594\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9579\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9554\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9548\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9532\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9545\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.9549\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9547\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 0s 999us/step - loss: 0.9524\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/100\n",
      "37/37 [==============================] - 0s 928us/step - loss: 15.6784\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 946us/step - loss: 10.9921\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 834us/step - loss: 6.6648\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 1000us/step - loss: 3.7605\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 999us/step - loss: 2.4820\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.0876\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 1.9138\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 919us/step - loss: 1.7816\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 0s 999us/step - loss: 1.6667\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 973us/step - loss: 1.5697\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 1.4889\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 1.4164\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 0s 918us/step - loss: 1.3581\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 0s 999us/step - loss: 1.3054\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 1.2613\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 1.2225\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 0s 999us/step - loss: 1.1930\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1642\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1462\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1257\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1095\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0987\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0890\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0803\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0747\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 1.0637\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 1.0586\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0528\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0465\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0432\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0379\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 1.0345\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 0s 918us/step - loss: 1.0323\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 1.0263\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 0s 918us/step - loss: 1.0243\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0282\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0185\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0168\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0121\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0110\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0065\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0059\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 1.0038\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 1.0005\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0001\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9967\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0063\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9968\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9898\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.9900\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 0.9878\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 0s 999us/step - loss: 0.9909\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 0s 918us/step - loss: 0.9850\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 0.9848\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 0.9817\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 0s 918us/step - loss: 0.9814\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 0.9794\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.9746\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.9779\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 0s 999us/step - loss: 0.9806\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.9752\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.9740\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 0s 918us/step - loss: 0.9704\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.9692\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 0s 999us/step - loss: 0.9689\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 0s 1000us/step - loss: 0.9661\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 0s 973us/step - loss: 0.9649\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 0.9631\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9644\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9592\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.9704\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9600\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 0s 999us/step - loss: 0.9654\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9571\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9555\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9549\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 0s 973us/step - loss: 0.9533\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 0s 864us/step - loss: 0.9528\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 0.9518\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9549\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 0s 999us/step - loss: 0.9494\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.9480\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9495\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.9618\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9447\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 0s 999us/step - loss: 0.9488\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9445\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 0.9440\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 0.9450\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 0s 946us/step - loss: 0.9436\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 0.9417\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9463\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 972us/step - loss: 0.9394\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 0s 972us/step - loss: 0.9404\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - 0s 891us/step - loss: 0.9414\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.9411\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9370\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 0.9387\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 0s 918us/step - loss: 0.9386\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 0s 945us/step - loss: 0.9363\n",
      "10/10 [==============================] - 0s 859us/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(YourModel, X, y, cv=5, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9130231736928758\n"
     ]
    }
   ],
   "source": [
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 24.6419\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 16.5267\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 9.9569\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 5.3877\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 2.8815\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.8172\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 1.4805\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 1.3926\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.3586\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 1.3340\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 1.3095\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.2883\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.2658\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 1.2457\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.2289\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 1.2110\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.1945\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.1780\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.1671\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.1501\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 1.1387\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.1272\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 1.1177\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 1.1061\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 1.0966\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.0875\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.0794\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.0711\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 1.0649\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.0585\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 1.0514\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 1.0440\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 1.0396\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 1.0330\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 1.0281\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0239\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 1.0204\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.0172\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 1.0116\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.0068\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 1.0021\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.0002\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.9963\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9938\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9925\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9890\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9870\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9853\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9823\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9836\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9790\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 1000us/step - loss: 0.9778\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9752\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 0.9741\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9715\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9718\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 795us/step - loss: 0.9710\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9737\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9673\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9644\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.9636\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9625\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.9623\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 795us/step - loss: 0.9639\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9601\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.9580\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.9585\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9585\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 773us/step - loss: 0.9541\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.9559\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9537\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 791us/step - loss: 0.9516\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.9509\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9515\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9493\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 767us/step - loss: 0.9490\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.9470\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9474\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 834us/step - loss: 0.9435\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.9428\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9418\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9416\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 772us/step - loss: 0.9431\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.9385\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.9378\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 825us/step - loss: 0.9375\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9366\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9353\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9344\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.9347\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9324\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9338\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 758us/step - loss: 0.9311\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9336\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9305\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.659 - 0s 789us/step - loss: 0.9286\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9341\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.9259\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9345\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9400\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002BCA0BAED30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0175\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 832us/step - loss: 3.7648\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 825us/step - loss: 2.2304\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 1.8947\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 1.7695\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.6580\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 856us/step - loss: 1.5626\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 1.4815\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 1.4039\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 1.3400\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 1.2807\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.2296\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 1.1866\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 1.1531\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.1221\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 1.0966\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 1.0777\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 1.0627\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 1.0485\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 1.0434\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0273\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 1.0170\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.0114\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 1.0038\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9983\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.9920\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.9902\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.9876\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9844\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9819\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9711\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 784us/step - loss: 0.9752\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.9662\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9583\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9562\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 759us/step - loss: 0.9546\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9489\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 765us/step - loss: 0.9502\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9432\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 790us/step - loss: 0.9438\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9365\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9341\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9356\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9301\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9269\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9244\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9188\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9171\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9154\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.9189\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.9081\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9088\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9051\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9009\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8948\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8938\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.8881\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8860\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.8821\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 808us/step - loss: 0.8788\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8754\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8748\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8728\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.8722\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 777us/step - loss: 0.8687\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8701\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8607\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8596\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8608\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 776us/step - loss: 0.8560\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 825us/step - loss: 0.8505\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8500\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.8468\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8459\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 825us/step - loss: 0.8447\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8441\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8385\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.8372\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8371\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8358\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.835 - 0s 1ms/step - loss: 0.8357\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8324\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8345\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 817us/step - loss: 0.8296\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8286\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8267\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8270\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.8233\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8240\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 847us/step - loss: 0.8239\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.8269\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8242\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 818us/step - loss: 0.8228\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8193\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8175\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8189\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8166\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 777us/step - loss: 0.8169\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8164\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 791us/step - loss: 0.8202\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8242\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002BC9E414A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1060\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 801us/step - loss: 8.6882\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 835us/step - loss: 4.8717\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 2.9175\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 2.3520\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 2.1331\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 1.9765\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.8424\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 821us/step - loss: 1.7249\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 1.6268\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.5428\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 835us/step - loss: 1.4751\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.4238\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.3743\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 935us/step - loss: 1.3319\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.2886\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.2537\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 958us/step - loss: 1.2213\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.1942\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.1664\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 1.1425\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 1.1197\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 1.1029\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.0910\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 851us/step - loss: 1.0693\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.0574\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 1.0453\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.0334\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 856us/step - loss: 1.0255\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 1.0149\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 1.0118\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 1.0049\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9954\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.9912\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9867\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9784\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9772\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 761us/step - loss: 0.9698\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9713\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9658\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9563\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9554\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9585\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9472\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.9582\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9406\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.9406\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9354\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9343\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.9300\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9291\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9259\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 0.9239\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9225\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9183\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9187\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 0.9203\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9132\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9152\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9106\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 802us/step - loss: 0.9132\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9099\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9098\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9022\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.8984\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.8993\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9012\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.9015\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 899us/step - loss: 0.8957\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8917\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8921\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8974\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8918\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 849us/step - loss: 0.8889\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8884\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.8863\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8851\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 940us/step - loss: 0.8841\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8832\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8829\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8806\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8839\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 832us/step - loss: 0.8869\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.8800\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.8784\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 922us/step - loss: 0.8786\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 629us/step - loss: 0.8785\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8782\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 878us/step - loss: 0.8838\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8722\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8745\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8744\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 813us/step - loss: 0.8740\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.8707\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8719\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 965us/step - loss: 0.8707\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8684\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8667\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8669\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.8688\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 878us/step - loss: 0.8737\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002BC9E4688B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0012\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 744us/step - loss: 2.1564\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.8416\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.6523\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.5072\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.4064\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 801us/step - loss: 1.3252\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.2602\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 834us/step - loss: 1.2084\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 1.1658\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 1.1267\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 944us/step - loss: 1.0912\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0620\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 1.0394\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 1.0185\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.0002\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 791us/step - loss: 0.9857\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9747\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9636\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9509\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9447\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9383\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.9380\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 872us/step - loss: 0.9306\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.9213\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.9186\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 0.9119\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.9140\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9068\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.9066\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 0.9118\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9010\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8959\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8971\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8954\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8923\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8862\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.8846\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.8900\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8883\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8798\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8755\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.8763\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8742\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.8709\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.8710\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 794us/step - loss: 0.8692\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8648\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8654\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8635\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 0.8623\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8656\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.8628\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8587\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8587\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8534\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.8575\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8534\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8495\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8571\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 790us/step - loss: 0.8481\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8475\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8477\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8506\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8489\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8441\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8473\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 847us/step - loss: 0.8424\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8415\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 739us/step - loss: 0.8475\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 794us/step - loss: 0.8440\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8391\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 812us/step - loss: 0.8418\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8428\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8435\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8475\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 825us/step - loss: 0.8359\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8400\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8412\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8373\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 815us/step - loss: 0.8426\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8419\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8350\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 915us/step - loss: 0.8360\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.8368\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.8352\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.8320\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8343\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8354\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8368\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8327\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8304\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8363\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 787us/step - loss: 0.8366\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8317\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 835us/step - loss: 0.8341\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8269\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 854us/step - loss: 0.8383\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8276\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8300\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 791us/step - loss: 0.8354\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002BC9C60E9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1512\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 771us/step - loss: 7.7042\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 4.8597\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 3.0464\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 2.1531\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 1.8207\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 889us/step - loss: 1.7064\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.6450\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.5955\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.5483\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.5072\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.4640\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.4238\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 1.3851\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 1.3492\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.3172\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 1.2877\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 892us/step - loss: 1.2563\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.2260\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 1.1948\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 1.1682\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 1.1483\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 1.1272\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 1.1109\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0938\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 1.0802\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 1.0702\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0591\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 1.0465\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0394\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 1.0309\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0249\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0160\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 1.0168\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0041\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0014\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9957\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 952us/step - loss: 0.9927\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 695us/step - loss: 0.9869\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.9841\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.9788\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 717us/step - loss: 0.9774\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 0.9765\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9743\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9699\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.9704\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.9625\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9645\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.9572\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9577\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9639\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9519\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.9501\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.9467\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.9463\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9442\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9411\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9396\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9391\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9353\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9342\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9381\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9313\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9314\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.9296\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9233\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9227\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 747us/step - loss: 0.9198\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.9199\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.9147\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9151\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9100\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.9090\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.9026\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.9060\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9053\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9029\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8991\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 792us/step - loss: 0.8976\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8963\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8950\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8948\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.8922\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.8917\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8885\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8914\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8858\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8864\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 0.8835\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8818\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8808\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8790\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8791\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8853\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8779\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8753\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8759\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8747\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8749\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8735\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8754\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002BCA0BC2940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9880\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 763us/step - loss: 1.5817\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 825us/step - loss: 1.2882\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.2511\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 1.2239\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 1.1976\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.1769\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 1.1566\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 1.1434\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.1268\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.1086\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.0982\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.0941\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 1.0794\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.0699\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.0642\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.0531\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.0458\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.0374\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 1.0314\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.0359\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 801us/step - loss: 1.0224\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.0176\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.0130\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.0083\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 1.0037\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 756us/step - loss: 1.0016\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.9918\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9897\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9832\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 966us/step - loss: 0.9882\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9801\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9725\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9718\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.9658\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9646\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9643\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9543\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.9568\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.9412\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9507\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9358\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9305\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.9310\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9275\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 869us/step - loss: 0.9194\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.9206\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9154\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9134\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 801us/step - loss: 0.9149\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9066\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9067\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 748us/step - loss: 0.9004\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8933\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 855us/step - loss: 0.8992\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.709 - 0s 1ms/step - loss: 0.8930\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8960\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 740us/step - loss: 0.8928\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8845\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 791us/step - loss: 0.8826\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8824\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 790us/step - loss: 0.8860\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8767\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8736\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8731\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 843us/step - loss: 0.8688\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8683\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8682\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8638\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8655\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8615\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8603\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8608\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8579\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 771us/step - loss: 0.8552\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8549\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 769us/step - loss: 0.8549\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8537\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 791us/step - loss: 0.8514\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8484\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.107 - 0s 934us/step - loss: 0.8529\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 900us/step - loss: 0.8464\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 739us/step - loss: 0.8561\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8498\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8425\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.8483\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.8468\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.8452\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8451\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 815us/step - loss: 0.8389\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.8428\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.8386\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.8426\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.8382\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.8369\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 860us/step - loss: 0.8352\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.8336\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.8399\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.8331\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.8336\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8322\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002BCA0BC21F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1584\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 771us/step - loss: 1.8815\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 754us/step - loss: 1.5589\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 1.4504\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.3749\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.3153\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.2693\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.2302\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 1.1966\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.1679\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.1428\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 1.1257\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 1.1014\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 787us/step - loss: 1.0864\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.0718\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.0536\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 1.0433\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.0366\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.0220\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.0137\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.0057\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.0010\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9955\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9841\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.785 - 0s 891us/step - loss: 0.9783\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.9744\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9722\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 741us/step - loss: 0.9626\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9590\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9541\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.9524\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9452\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 0.9470\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 847us/step - loss: 0.9400\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9346\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.9308\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 733us/step - loss: 0.9276\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9244\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9200\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9207\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9156\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9145\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 763us/step - loss: 0.9124\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.9092\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9049\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9013\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.8974\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.8952\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8958\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.8926\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 852us/step - loss: 0.8884\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8879\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8877\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.8856\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8827\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8774\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8782\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8744\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8734\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8759\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8725\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 870us/step - loss: 0.8709\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8693\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.8669\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8631\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8652\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 734us/step - loss: 0.8590\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8615\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8608\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8600\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8597\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 825us/step - loss: 0.8577\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8566\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8584\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8555\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8560\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8558\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8503\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8556\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8533\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8488\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8482\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.8499\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8464\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 892us/step - loss: 0.8456\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 761us/step - loss: 0.8480\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8429\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8457\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8426\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8419\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8431\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8363\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8409\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.8367\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 793us/step - loss: 0.8377\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8354\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8357\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8323\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8319\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 0.8311\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8315\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002BCA0D91B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0318\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 822us/step - loss: 29.9337\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 16.2499\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 8.1839\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 3.6363\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 1.9419\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 887us/step - loss: 1.5702\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.4986\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.4564\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.4211\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.3884\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.474 - 0s 847us/step - loss: 1.3604\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 1.3359\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 1.3150\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.2930\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.2779\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.2636\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 1.2516\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.2404\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.2315\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.2230\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 804us/step - loss: 1.2158\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.2091\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.2012\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.1924\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.1868\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 848us/step - loss: 1.1800\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.1768\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.1678\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 873us/step - loss: 1.1619\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.1585\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 1.1505\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 1.1447\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.1377\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 1.1339\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.1302\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.1243\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 1.1145\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.1101\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.1082\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 841us/step - loss: 1.1007\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.0922\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.0877\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 813us/step - loss: 1.0836\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 1.0790\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 1.0722\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 1.0702\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 1.0638\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 717us/step - loss: 1.0621\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 1.0561\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0514\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 866us/step - loss: 1.0463\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 1.0457\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 1.0372\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 812us/step - loss: 1.0317\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 1.0308\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 1.0231\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 1.0209\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 1.0156\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 1.0131\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0090\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0067\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0033\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.9985\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9940\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.9924\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.9887\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9854\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9834\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 0.9777\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.9767\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9746\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9711\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9697\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9636\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9614\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9578\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.9606\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.9540\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9503\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9486\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 825us/step - loss: 0.9465\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.9434\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9428\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9397\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 0.9393\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9411\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9356\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9311\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 777us/step - loss: 0.9280\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9289\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9255\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9256\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.9227\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.9227\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 822us/step - loss: 0.9205\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9175\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9190\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9178\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9199\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 776us/step - loss: 0.9190\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002BC9E467280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4272\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 57.2850\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 40.1241\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 28.1475\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 19.1540\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 12.5387\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 7.9279\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 5.0388\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 798us/step - loss: 3.4149\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 2.5878\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 934us/step - loss: 2.1976\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 798us/step - loss: 2.0102\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.9035\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 1.8262\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7607\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 901us/step - loss: 1.7002\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.6432\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 806us/step - loss: 1.5872\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.5298\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 759us/step - loss: 1.4791\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.4336\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 769us/step - loss: 1.3887\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.3494\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 769us/step - loss: 1.3134\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.2854\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.2534\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.2285\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 755us/step - loss: 1.2034\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.1802\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 768us/step - loss: 1.1603\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 1.1421\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.1252\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.1094\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 755us/step - loss: 1.0944\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.0810\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.0699\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 1.0604\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.0485\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 1.0393\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0294\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0218\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0155\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0093\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0009\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9951\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 1000us/step - loss: 0.9898\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9870\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.9799\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9791\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9714\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9670\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.9628\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.9598\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9572\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.9528\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9485\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9468\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.9435\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9440\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9387\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9351\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9339\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9310\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 0.9289\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9275\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9265\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.9249\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.9218\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9203\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.9208\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9189\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9175\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9146\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9143\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9111\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9155\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 0.9137\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.9087\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9090\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9057\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9045\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9043\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9126\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9017\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9031\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8998\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9005\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9022\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8962\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8962\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8939\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8968\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 923us/step - loss: 0.8944\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8920\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8920\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8918\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8892\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8902\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8971\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8918\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.8877\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002BC9C959160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0679\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 873us/step - loss: 20.2262\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 12.8696\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 7.4002\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8107\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 2.2038\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.7741\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 1.6313\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.5375\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.4601\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 792us/step - loss: 1.3951\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 1.3376\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.2898\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 787us/step - loss: 1.2489\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 1.2110\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.1790\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 791us/step - loss: 1.1505\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 1.1288\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.1074\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 1.0904\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.0731\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0605\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.0477\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.0367\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0253\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.0174\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.0081\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9997\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9930\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9852\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 763us/step - loss: 0.9834\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9748\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9689\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9640\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9616\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9569\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9507\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9490\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9439\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9413\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9335\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9297\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 0.9267\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9254\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.9251\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9175\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9152\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.9153\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9112\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 748us/step - loss: 0.9116\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9086\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9064\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9042\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9020\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9014\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9005\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.8982\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.8954\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8928\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.8955\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.8897\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8883\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 764us/step - loss: 0.8912\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8929\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.8872\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 935us/step - loss: 0.8860\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.8812\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.8805\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.8800\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8834\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8784\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 0.8736\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8739\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8748\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8731\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8692\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.8718\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8690\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8692\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8672\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 793us/step - loss: 0.8756\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8673\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8661\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8651\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8671\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8639\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.8624\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8617\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 808us/step - loss: 0.8588\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8578\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8556\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 790us/step - loss: 0.8575\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8587\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8555\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8534\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8561\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8534\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8568\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8573\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 891us/step - loss: 0.8516\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8519\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002BC9DB8F0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0049\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 28.0046\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 19.6475\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 12.6646\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 7.1583\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 3.6835\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 849us/step - loss: 2.1524\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.6449\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.4620\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.3605\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.2850\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.2236\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.1712\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 800us/step - loss: 1.1294\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 1.0923\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 790us/step - loss: 1.0632\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.0383\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.0190\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.0034\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 935us/step - loss: 0.9908\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9804\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.9731\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 0.9657\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 786us/step - loss: 0.9590\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9539\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9501\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9467\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 802us/step - loss: 0.9425\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.9394\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9367\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9342\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9323\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9300\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.9286\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9280\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.9242\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9204\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 820us/step - loss: 0.9193\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.9187\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9157\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9137\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9107\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9080\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.9086\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.9032\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9030\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.9019\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8975\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8949\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 882us/step - loss: 0.8929\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.8904\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.8886\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8885\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.8880\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8814\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 923us/step - loss: 0.8779\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8750\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8719\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 914us/step - loss: 0.8707\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 850us/step - loss: 0.8692\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8672\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.8662\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8645\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 870us/step - loss: 0.8630\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8590\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.8601\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 892us/step - loss: 0.8564\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8560\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8536\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.8548\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8534\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8498\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8510\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.8460\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8453\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8503\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8462\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8438\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8409\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8458\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8405\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8518\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8399\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8388\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.8368\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8390\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8379\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8359\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 913us/step - loss: 0.8377\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8366\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 0.8336\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8326\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8337\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 825us/step - loss: 0.8312\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 783us/step - loss: 0.8325\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8303\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8292\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8306\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8363\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 799us/step - loss: 0.8300\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8327\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002BC9DB8F040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0081\n",
      "Epoch 1/100\n",
      " 1/46 [..............................] - ETA: 0s - loss: 18.6725WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 17.8474\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 13.5618\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 9.7308\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 6.2124\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 3.5870\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 2.1036\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.5411\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.3927\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 777us/step - loss: 1.3553\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.3382\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.451 - 0s 869us/step - loss: 1.3220\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.3066\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.2892\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.2736\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.2572\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.2402\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.2241\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 1.2089\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.1926\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.1761\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 1.1614\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 1.1448\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.1293\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.1163\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.1000\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 825us/step - loss: 1.0860\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.0676\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 1.0530\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.0378\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.0234\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 1.0100\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.9994\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9881\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 0.9815\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 795us/step - loss: 0.9738\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9669\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9631\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9591\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9538\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.9492\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9458\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.9428\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9400\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9382\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.9363\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.9323\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.9309\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9307\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9292\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.9264\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.9263\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9226\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9209\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9186\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9173\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9162\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9157\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9129\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9135\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9120\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.9117\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.9096\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9126\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 0.9082\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9061\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.9049\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.9072\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.9020\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9022\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 786us/step - loss: 0.9003\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.8984\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.8973\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9006\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 782us/step - loss: 0.8975\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 796us/step - loss: 0.8965\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8957\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 809us/step - loss: 0.8960\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8955\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 768us/step - loss: 0.8956\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8941\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 769us/step - loss: 0.8959\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8943\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 738us/step - loss: 0.8929\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8905\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 799us/step - loss: 0.8906\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8955\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8844\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8904\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8869\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8870\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8855\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8853\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8863\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 783us/step - loss: 0.8837\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.8881\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8819\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8822\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 791us/step - loss: 0.8814\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8788\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8852\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002BC9DB85700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8402\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 795us/step - loss: 2.8892\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 1.9376\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7411\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.5888\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.4686\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 1.3611\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.2803\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.2200\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 1.1634\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.1213\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0843\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 1.0558\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 1.0276\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 888us/step - loss: 1.0079\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.9887\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 870us/step - loss: 0.9786\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9589\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9498\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.9405\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.9389\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.9244\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.9191\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.9150\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.9156\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9097\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.9033\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8985\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8966\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8983\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8887\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8884\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8881\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8839\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8875\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8823\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8765\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8829\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8773\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8802\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8756\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8686\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8686\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8672\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8687\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8646\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8660\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8631\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8633\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.834 - 0s 1ms/step - loss: 0.8615\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8610\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8549\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8618\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8545\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8538\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8559\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8490\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8491\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8548\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8498\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8490\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8490\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8517\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8450\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8476\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8495\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8435\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8431\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8435\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8406\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8473\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8445A: 0s - loss: 0.848\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8417\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8397\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8404\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8406\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8383\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8451\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8411\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8393\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8416\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8371\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8403\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8389\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.8405\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8387\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 979us/step - loss: 0.8467\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8360\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.8361\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8385\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 1000us/step - loss: 0.8400\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8356\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8391\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 862us/step - loss: 0.8420\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.8415\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.8333\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.8330\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8340\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8327\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 960us/step - loss: 0.8381\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 868us/step - loss: 0.8352\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002BCA0D6CB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0609\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 900us/step - loss: 6.2631\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 854us/step - loss: 3.8951\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 2.5379\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.8685\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 769us/step - loss: 1.6064\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.4694\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.3727\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 1.2983\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 1.2433\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.398 - 0s 1000us/step - loss: 1.2001\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.1655\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 1.1350\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 840us/step - loss: 1.1112\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 1.0865\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.0629\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 1.0403\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0203\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 967us/step - loss: 1.0083\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.9850\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9708\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9574\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9480\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9441\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9369\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 879us/step - loss: 0.9352\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9270\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9264\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9238\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9173\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9114\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9102\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.908 - 0s 1ms/step - loss: 0.9054\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9069\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9003\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 882us/step - loss: 0.9002\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.8969\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.8948\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.8909\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.8918\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8953\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.8908\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.8841\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.8864\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8796\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8803\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8779\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8763\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8762\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.8821\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.8731\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 0.8727\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.8707\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 956us/step - loss: 0.8709\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.8663\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8685\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 932us/step - loss: 0.8656\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 849us/step - loss: 0.8655\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 717us/step - loss: 0.8681\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.8631\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 739us/step - loss: 0.8658\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 739us/step - loss: 0.8620\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.8658\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.8595\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8616\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 814us/step - loss: 0.8602\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.8592\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8591\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 878us/step - loss: 0.8666\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8620\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8579\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 783us/step - loss: 0.8584\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.8532\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.8593\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.8540\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8541\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 739us/step - loss: 0.8556\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8508\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8525\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 947us/step - loss: 0.8502\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.8482\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.8631\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 739us/step - loss: 0.8513\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.8514\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 739us/step - loss: 0.8522\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 0.8501\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 0.8496\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.8485\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.8500\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8468\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8428\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.8480\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 0.8457\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 714us/step - loss: 0.8447\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8456\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 0.8440\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.8448\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 739us/step - loss: 0.8439\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 0.8432\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 739us/step - loss: 0.8442\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 0.8434\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002BC9F56C310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0342\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 761us/step - loss: 9.0992\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 810us/step - loss: 5.6387\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 739us/step - loss: 3.6474\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 2.4130\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 688us/step - loss: 1.8217\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 1.5366\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 1.3659\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 717us/step - loss: 1.2595\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 1.1832\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 1.1235\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 717us/step - loss: 1.0724\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 1.0335\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 1.0004\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.9749\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.9586\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9383\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9261\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 956us/step - loss: 0.9155\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.9175\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9029\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8983\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 717us/step - loss: 0.8973\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 739us/step - loss: 0.8945\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 695us/step - loss: 0.8903\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 0.8882\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8866\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8808\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8802\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.8744\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.8771\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 739us/step - loss: 0.8733\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8698\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 0.8839\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8708\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8729\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8647\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 0.8634\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8629\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.8605\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.8587\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8667\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 804us/step - loss: 0.8612\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.8593\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 674us/step - loss: 0.8552\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 739us/step - loss: 0.8544\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 717us/step - loss: 0.8543\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 739us/step - loss: 0.8493\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 738us/step - loss: 0.8508\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 739us/step - loss: 0.8509\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 739us/step - loss: 0.8479\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 717us/step - loss: 0.8544\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 0.8543\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8460\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 638us/step - loss: 0.8485\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 739us/step - loss: 0.8466\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 0.8467\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.8431\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 674us/step - loss: 0.8425\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 0.8439\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 739us/step - loss: 0.8410\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 761us/step - loss: 0.8460\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 0.8417\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.8414\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.8430\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 717us/step - loss: 0.8458\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 0.8403\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.8442\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 962us/step - loss: 0.8370\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 696us/step - loss: 0.8472\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 717us/step - loss: 0.8453\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 717us/step - loss: 0.8412\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 739us/step - loss: 0.8374\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 0.8390\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 0.8391\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8394\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.8374\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 0.8331\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8351\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 760us/step - loss: 0.8340\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 739us/step - loss: 0.8339\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8419\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.8298\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8392\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.8425\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8340\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 695us/step - loss: 0.8380\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8412\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 675us/step - loss: 0.8369\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 739us/step - loss: 0.8325\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.8333\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8408\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 695us/step - loss: 0.8308\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8326\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8320\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8326\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 982us/step - loss: 0.8331\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8372\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8340\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 798us/step - loss: 0.8325\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8296\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002BCA0C0D1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0495\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 14.6737\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 9.9646\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 5.6329\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 2.9102\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.9628\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.7603\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 1.7004\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.6554\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.6092\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.5697\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.5309\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.4920\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.4547\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.4202\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.3879\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.3550\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.3254\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.2951\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 865us/step - loss: 1.2654\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 845us/step - loss: 1.2343\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.1979\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.1613\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.1229\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0927\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0709\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0511\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 1.0338\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0197\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 1.0071\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9975\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9891\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.9823\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.9773\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9714\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9663\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 945us/step - loss: 0.9620\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 999us/step - loss: 0.9570\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9529\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 843us/step - loss: 0.9500\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 739us/step - loss: 0.9451\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.9463\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.9426\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 929us/step - loss: 0.9387\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 828us/step - loss: 0.9365\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9382\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9359\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.9297\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9282\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9245\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9217\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.9220\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9196\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.9181\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.9154\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 773us/step - loss: 0.9206\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9174\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9140\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 769us/step - loss: 0.9094\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9114\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 790us/step - loss: 0.9075\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9058\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.9062\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9053\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.9020\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.9010\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8997\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8987\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.8991\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 874us/step - loss: 0.8955\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 1000us/step - loss: 0.8938\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8947\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 784us/step - loss: 0.8945\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 891us/step - loss: 0.8932\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 782us/step - loss: 0.8895\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8917\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8902\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 849us/step - loss: 0.8891\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8912\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8897\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8842\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 804us/step - loss: 0.8841\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8855\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 978us/step - loss: 0.8876\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.913 - 0s 826us/step - loss: 0.8885\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8845\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8816\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8826\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 853us/step - loss: 0.8814\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8816\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 934us/step - loss: 0.8892\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 813us/step - loss: 0.8765\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8815\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8798\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8783\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 869us/step - loss: 0.8780\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 847us/step - loss: 0.8780\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 913us/step - loss: 0.8752\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 826us/step - loss: 0.8757\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8758\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.8736\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002BC9E414820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0544\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "scores = cross_val_score(YourModel, X, y, cv=LeaveOneOut())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
